{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 1: Wine Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Load Data and \n",
    "Task 2: Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "dataset = load_wine()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test= train_test_split(dataset.data , dataset.target, random_state  = 2810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.66666667 0.66666667 0.73076923 0.73076923]\n",
      "The Generalisation accuracy is 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "print(cross_val_score(svc,X_train, y_train))\n",
    "print('The Generalisation accuracy is',np.mean(cross_val_score(svc,X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross Val error is 0.30769230769230765\n"
     ]
    }
   ],
   "source": [
    "print('The Cross Val error is',np.mean(1-cross_val_score(svc,X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Test Error rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error rate 0.37777777777777777\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)\n",
    "print('Test Error rate',1-svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Performance on the Test-set is worse than the performance on Cross_validation sets, this is largely due to small size of training set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:Creating Pipeline with different normalisation and Task 6: Predicting Labels and calculating Test-error rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pipeline = Pipeline([('scaler',MinMaxScaler()), ('svm',SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 1.0\n",
      "Test set score: 0.9555555555555556\n",
      "Best Parameters: {'svm__C': 1, 'svm__gamma': 1}\n",
      "The Test Error rate- 0.044444444444444446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'svm__C':[0.001,0.01,0.1,1,10,100], 'svm__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 1.0\n",
      "Test set score: 0.9333333333333333\n",
      "Best Parameters: {'svm__C': 1, 'svm__gamma': 0.01}\n",
      "The Test Error rate- 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "pipeline = Pipeline([('scaler',StandardScaler()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.9319088319088319\n",
      "Test set score: 0.9333333333333333\n",
      "Best Parameters: {'svm__C': 100, 'svm__gamma': 100}\n",
      "The Test Error rate- 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "pipeline = Pipeline([('scaler',Normalizer()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.9925925925925926\n",
      "Test set score: 0.9555555555555556\n",
      "Best Parameters: {'svm__C': 1, 'svm__gamma': 0.01}\n",
      "The Test Error rate- 0.044444444444444446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "pipeline = Pipeline([('scaler',RobustScaler()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Wine Dataset, MinMax appears to be best way to normalise as it is providing the best Cross-Validation accuracy and best Test set score. However,the difference between the performance MinMax and Standard Normalisation is not that big and both of them provide comparable results.Robust Scaler gives test-error rate equal to MinMax Scaler but it has lower Cross-validation accuracy. For the next task, I am going to use MinMax to preprocess data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7: Implementing Cross-Conformal Predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''For the implementaion of cross-conformal predictors, I have used CV = 5. I have calculated ranks for each caliberation fold and have added the rank for the other caliberation fold using a loop. Since, I have not created an augmented dataset, the way I have found the rank of each test sample for each caliberation set does not require me to subtract one from the rank as this way if my test sample for a given fold is the strangest, the rank will be zero already and hence no need to subtract 1.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler',MinMaxScaler()), ('svm',SVC())]) #Redefining Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(shuffle = True, random_state = 2810)\n",
    "grid1 = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_rank = np.zeros((len(X_test),3))\n",
    "for rest_index, fold_index in kf.split(X_train):\n",
    "    X_rest,X_fold = X_train[rest_index], X_train[fold_index]\n",
    "    y_rest,y_fold = y_train[rest_index], y_train[fold_index]\n",
    "    conformity_fold = np.zeros(len(y_fold))\n",
    "    grid1.fit(X_rest,y_rest)\n",
    "    conformity_scores  = grid1.decision_function(X_fold) \n",
    "    test_decision = grid1.decision_function(X_test)\n",
    "    for i in range(len(y_fold)):\n",
    "        conformity_fold[i] = conformity_scores[i,y_fold[i]]\n",
    "    for j in range(len(y_test)):\n",
    "        for k in range(3):\n",
    "            fold_rank[j,k] = fold_rank[j,k]+np.sum(test_decision[j,k] >= conformity_fold)\n",
    "p_value = (fold_rank+1)/(len(X_train)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error- 0.044444444444444446\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_train)\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "for i in range(len(p_value)):\n",
    "    pred_targets[i] = labels[np.argmax(p_value[i])]\n",
    "print('The Test Error-',np.mean(pred_targets != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8abaa2af10>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100)\n",
    "err = np.zeros(100)\n",
    "for k in range(100):\n",
    "    eps[k] = k/100\n",
    "    err[k] = 0\n",
    "    for j in range(len(y_test)):\n",
    "        if(p_value[j,y_test[j]]<= eps[k]):\n",
    "            err[k] = err[k]+1\n",
    "    err[k] = err[k]/len(y_test)\n",
    "plt.plot(eps,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg False P-Value is 0.008706467661691555\n"
     ]
    }
   ],
   "source": [
    "total = 0    \n",
    "for i in range(len(y_test)):\n",
    "    k = y_test[i]\n",
    "    for j in range(len(labels)):\n",
    "        if k!= j:\n",
    "            total =total+ p_value[i,j]\n",
    "avg_false_p = total/(len(p_value)*(len(labels)-1))\n",
    "print('Avg False P-Value is' ,avg_false_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 2: USPS Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Load Data and \n",
    "Task 2: Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_test = np.genfromtxt('/home/smith/Downloads/zip.test')\n",
    "data_train = np.genfromtxt('/home/smith/Downloads/zip.train')\n",
    "dataset = np.concatenate([data_train, data_test]) #merging the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test= train_test_split(dataset[:,1:] , dataset[:,0], random_state  = 2810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:Cross- Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97491039 0.96702509 0.96702509 0.97704448 0.96915352]\n",
      "The Generalisation accuracy is 0.9710317129736762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "print(cross_val_score(svc,X_train, y_train))\n",
    "print('The Generalisation accuracy is',np.mean(cross_val_score(svc,X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cross Val error is 0.028968287026323793\n"
     ]
    }
   ],
   "source": [
    "print('The Cross Val error is',np.mean(1-cross_val_score(svc,X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:Test error rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02537634408602152\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)\n",
    "print(1-svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Performance on the Test-set is similar to the performance on Cross_validation sets due to large size of training set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:Creating Pipeline with different normalisation and Task 6: Predicting Labels and Test error_rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.9695974041334342\n",
      "Test set score: 0.9724731182795698\n",
      "Best Parameters: {'svm__C': 10, 'svm__gamma': 0.01}\n",
      "The Test Error rate- 0.027526881720430108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pipeline = Pipeline([('scaler',MinMaxScaler()), ('svm',SVC())])\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid ={'svm__C':[0.001,0.01,0.1,1,10,100], 'svm__gamma':[0.001,0.01,0.1,1,10,100]}\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.9654386695669613\n",
      "Test set score: 0.9668817204301076\n",
      "Best Parameters: {'svm__C': 10, 'svm__gamma': 0.001}\n",
      "The Test Error rate- 0.033118279569892474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "pipeline = Pipeline([('scaler',StandardScaler()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.8808341946797077\n",
      "Test set score: 0.8838709677419355\n",
      "Best Parameters: {'svm__C': 100, 'svm__gamma': 0.001}\n",
      "The Test Error rate- 0.11612903225806452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "pipeline = Pipeline([('scaler',RobustScaler()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross_validation accuracy: 0.9731825591500696\n",
      "Test set score: 0.978494623655914\n",
      "Best Parameters: {'svm__C': 10, 'svm__gamma': 1}\n",
      "The Test Error rate- 0.021505376344086023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "pipeline = Pipeline([('scaler',Normalizer()), ('svm',SVC())])\n",
    "grid = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Best Cross_validation accuracy:', grid.best_score_)\n",
    "print('Test set score:', grid.score(X_test,y_test))\n",
    "print('Best Parameters:', grid.best_params_)\n",
    "print('The Test Error rate-',np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For USPS Dataset, Normaliser appears to be best way to normalise as it is providing the best Cross-Validation accuracy and best Test set score.Since, the USPS dataset contains images, it is required to standardize the brightness, or the brightness and contrast,\n",
    "for each image separately and thus we use Normaliser class for per-sample normalisation. For the next task, I am going to use Normalizer method to preprocess data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7: Implementing Cross-Conformal Predictors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler',Normalizer()), ('svm',SVC())]) #Redefining Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(shuffle = True, random_state = 2810)\n",
    "grid1 = GridSearchCV(pipeline, param_grid = param_grid, cv =5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test error rate is 0.025806451612903226\n"
     ]
    }
   ],
   "source": [
    "fold_rank = np.zeros((len(X_test),10))\n",
    "for rest_index, fold_index in kf.split(X_train):\n",
    "    X_rest,X_fold = X_train[rest_index], X_train[fold_index]\n",
    "    y_rest,y_fold = y_train[rest_index], y_train[fold_index]\n",
    "    conformity_fold = np.zeros(len(y_fold))\n",
    "    grid1.fit(X_rest,y_rest)\n",
    "    conformity_scores  = grid1.decision_function(X_fold) \n",
    "    test_decision = grid1.decision_function(X_test)\n",
    "    for i in range(len(y_fold)):\n",
    "        conformity_fold[i] = conformity_scores[i,int(y_fold[i])]\n",
    "    for j in range(len(y_test)):\n",
    "        for k in range(10):\n",
    "            fold_rank[j,k] = fold_rank[j,k]+np.sum(test_decision[j,k] >= conformity_fold) \n",
    "p_value = (fold_rank+1)/(len(X_train)+1)\n",
    "labels = np.unique(y_train)\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "for i in range(len(p_value)):\n",
    "    pred_targets[i] = labels[np.argmax(p_value[i])]\n",
    "print('The Test error rate is',np.mean(pred_targets != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average False P-value is  0.004598339146014124\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.zeros(100)\n",
    "err = np.zeros(100)\n",
    "for k in range(100):\n",
    "    eps[k] = k/100\n",
    "    err[k] = 0\n",
    "    for j in range(len(y_test)):\n",
    "        if(p_value[j,int(y_test[j])]<= eps[k]):\n",
    "            err[k] = err[k]+1\n",
    "    err[k] = err[k]/len(y_test)\n",
    "plt.plot(eps,err)\n",
    "total = 0    \n",
    "for i in range(len(y_test)):\n",
    "    k = y_test[i]\n",
    "    for j in range(len(labels)):\n",
    "        if k!= j:\n",
    "            total =total+ p_value[i,j]\n",
    "avg_false_p = total/(len(p_value)*(len(labels)-1))\n",
    "print('Average False P-value is ',avg_false_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "Task 3: \n",
    "        \n",
    "        Generalisation accuracy for Wine Dataset = 0.6923076923076923\n",
    "\n",
    "        Generalisation accuracy for USPS Dataset = 0.9710317129736762\n",
    "        \n",
    "Task 4: \n",
    "\n",
    "        Test error rate for Wine Dataset = 0.37777777777777777\n",
    "\n",
    "        Test error rate for USPS Dataset = 0.02537634408602152\n",
    "        \n",
    "Task 6: \n",
    "         \n",
    "        Test error rate for Wine Dataset using MinMax = 0.044444444444444446\n",
    "\n",
    "        Test error rate for USPS Dataset using MinMax = 0.027526881720430108\n",
    "        \n",
    "        Test error rate for Wine Dataset using Normaliser = 0.06666666666666667\n",
    "        \n",
    "        Test error rate for USPS Dataset using Normaliser = 0.021505376344086023\n",
    "        \n",
    "        Test error rate for Wine Dataset using RobustScaler = 0.044444444444444446\n",
    "        \n",
    "        Test error rate for USPS Dataset using RobustScaler = 0.11612903225806452\n",
    "        \n",
    "        Test error rate for Wine Dataset using StandardScaler = 0.06666666666666667\n",
    "        \n",
    "        Test error rate for USPS Dataset using StandardScaler = 0.033118279569892474\n",
    "        \n",
    "        \n",
    "Task 7: \n",
    "\n",
    "        Average False P-value for Wine dataset = 0.008706467661691555\n",
    "\n",
    "        Average False P-value for USPS dataset = 0.004598339146014124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "1) The Wine Dataset being a small dataset can give better test-error rate for StandardScaler, MinMax Scaler if random state is changed. \n",
    "\n",
    "2) With the increase in size of the dataset, the difference between generalisation accuracy and accuracy on test-set becomes lesser. Increased size of training set has reduced the error rate greatly as well.\n",
    "\n",
    "3) The caliberation curve is affected by the size of our training set significantly, it can be apparant from the caliberation curve we obtained from the two datasets. USPS Dataset being an enormous dataset provides a caliberation curve which is close to the ideal calioberation curve i.e  the main diagonal of the square [0,1]^2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Comment:*** I tried to find the optimal number of folds for the crossconformal predictor, It is generally advised to use k =[5,10] number of folds for crossvalidation. Since the approach for conformal predictors is different than other machine learning algorithms, I am not sure if it is the right thing to use the same values of K. But, I found that for these values of K, the validity and efficiency were achevied. Using USPS dataset, I found K =10 to be the optimal number of folds. I also tried to do something like K = n, number of folds where n = size of training set which I beleived to work as Leave-one-out counterpart for the cross-confromal predictors, but the K-fold library did not let me do that. I tried some other ways and using smaller dataset, I found that for that setting the validity of our cross-conformal predictior may be violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
