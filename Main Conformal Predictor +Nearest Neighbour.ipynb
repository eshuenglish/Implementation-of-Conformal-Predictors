{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implementing nearest neighbour**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, for Iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "print(iris_data.feature_names)\n",
    "print(iris_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,random_state = 2810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate euclidean distance\n",
    "def E_len(x,y):\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum = sum +(x[i]-y[i])**2\n",
    "    norm = sum**0.5\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(len(X_test))\n",
    "a = np.zeros(len(X_train))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_train)):\n",
    "        a[j] = E_len(X_train[j], X_test[i])\n",
    "    pos = np.argmin(a)\n",
    "    y_pred[i] = y_train[pos] \n",
    "test_error_rate = np.mean(y_pred != y_test)\n",
    "no_of_errors = np.sum(y_pred!=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error rate is:  0.07894736842105263\n",
      "Number of Errors:  3\n"
     ]
    }
   ],
   "source": [
    "print('The Test Error rate is: ',test_error_rate)\n",
    "print('Number of Errors: ',no_of_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**applying nearest neighbor to Ionosphere dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('/home/smith/Downloads/ionosphere.txt', delimiter =',')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:,:34],data[:,-1], random_state = 2810)\n",
    "y_pred = np.zeros(len(X_test))\n",
    "a = np.zeros(len(X_train))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_train)):\n",
    "        a[j] = E_len(X_train[j], X_test[i])\n",
    "    pos = np.argmin(a)\n",
    "    y_pred[i] = y_train[pos] \n",
    "test_error_rate = np.mean(y_pred != y_test)\n",
    "no_of_errors = np.sum(y_pred!=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error rate is:  0.10227272727272728\n",
      "Number of Errors:  9\n"
     ]
    }
   ],
   "source": [
    "print('The Test Error rate is: ',test_error_rate)\n",
    "print('Number of Errors: ',no_of_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**part 2: Implementation of conformal predictors based on nearest neighbour**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**first, for Iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,random_state = 2810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pvalue(aug_set,aug_targets):\n",
    "    for i in range(len(aug_set)):\n",
    "        a = np.array([])\n",
    "        c = np.array([])\n",
    "        for j in range(len(aug_set)):\n",
    "            if (i!=j) & (aug_targets[i] == aug_targets[j]):\n",
    "                b = (np.sum((aug_set[i]-aug_set[j])**2))**0.5\n",
    "                a = np.append(a,b)\n",
    "            elif (i!=j) & (aug_targets[i] != aug_targets[j]):\n",
    "                b = (np.sum((aug_set[i]-aug_set[j])**2))**0.5\n",
    "                c = np.append(c,b)       \n",
    "        if (np.min(c)==0)&(np.min(a)==0):\n",
    "            conformity_scores[i] = 0\n",
    "        elif np.min(a)==0:\n",
    "            conformity_scores[i] = inf\n",
    "        else:\n",
    "            conformity_scores[i] = np.min(c)/np.min(a)\n",
    "\n",
    "    test_conformity = conformity_scores[-1]\n",
    "    rank = np.sum(test_conformity >= conformity_scores)\n",
    "    p = rank/len(aug_set)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average False_Pvalue is:  0.009548206800186318\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_train)\n",
    "p_values =np.zeros((len(X_test), len(labels)))\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "conformity_scores = np.zeros(len(X_train)+1)\n",
    "for i in range(len(X_test)):\n",
    "    augmented_set = np.append(X_train, [X_test[i]],axis = 0)\n",
    "    for j in range(len(labels)):\n",
    "        augmented_targets = np.append(y_train, labels[j])\n",
    "        p_values[i][j] = calc_pvalue(augmented_set,augmented_targets)\n",
    "for i in range(len(p_values)):\n",
    "    pred_targets[i] = labels[np.argmax(p_values[i])]\n",
    "sum = 0    \n",
    "for i in range(len(p_values)):\n",
    "    k = int(pred_targets[i])\n",
    "    for j in range(len(labels)):\n",
    "        if p_values[i,k]!= p_values[i,j]:\n",
    "            sum =sum+ p_values[i,j]\n",
    "avg_false_p = sum/(len(p_values)*(len(labels)-1))\n",
    "print('The average False_Pvalue is: ',avg_false_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test error rate is : 0.07894736842105263\n",
      "Number of Misclassification : 3\n",
      "Success rate is : 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print('The Test error rate is :',np.mean(pred_targets != y_test))\n",
    "print('Number of Misclassification :',np.sum(pred_targets!=y_test))\n",
    "print('Success rate is :',np.mean(pred_targets == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validity : Success rate on test set is 92.10%, which means our conformal prediction model is valid about 90% on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**applying conformal prediction to Ionosphere dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:,:34],data[:,-1], random_state = 2810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average False_Pvalue is:  0.09999139118457302\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_train)\n",
    "p_values =np.zeros((len(X_test), len(labels)))\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "conformity_scores = np.zeros(len(X_train)+1)\n",
    "for i in range(len(X_test)):\n",
    "    augmented_set = np.append(X_train, [X_test[i]],axis = 0)\n",
    "    for j in range(len(labels)):\n",
    "        augmented_targets = np.append(y_train, labels[j])\n",
    "        p_values[i][j] = calc_pvalue(augmented_set,augmented_targets)\n",
    "for i in range(len(p_values)):\n",
    "    pred_targets[i] = labels[np.argmax(p_values[i])]\n",
    "sum = 0    \n",
    "for i in range(len(p_values)):\n",
    "    k = int(pred_targets[i])\n",
    "    for j in range(len(labels)):\n",
    "        if p_values[i,k]!= p_values[i,j]:\n",
    "            sum =sum+ p_values[i,j]\n",
    "avg_false_p = sum/(len(p_values)*(len(labels)-1))\n",
    "print('The average False_Pvalue is: ',avg_false_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test error rate is : 0.10227272727272728\n",
      "Number of Misclassification : 9\n",
      "Success rate is : 0.8977272727272727\n"
     ]
    }
   ],
   "source": [
    "print('The Test error rate is :',np.mean(pred_targets != y_test))\n",
    "print('Number of Misclassification :',np.sum(pred_targets!=y_test))\n",
    "print('Success rate is :',np.mean(pred_targets == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validity : Success rate on test set is 89.77%, which means our conformal prediction model is valid more than 85% on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifying convention for 0/0**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " We can only get 0/0 if nearest distance with in the same class as well as the nearest distance to a different class 0. If this happens that would mean two test sample with different labels, which is a very strange case. Assigning 0 to this convention would mean having rank 1 and hence the least P-value which singnifies the strangeness of the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using different conformity measures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**implementing nearest distance within class conformity measure for iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,random_state = 2810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pvalue_2(aug_set,aug_targets):\n",
    "    for i in range(len(aug_set)):\n",
    "        a = np.array([])\n",
    "        for j in range(len(aug_set)):\n",
    "            if (i!=j) & (aug_targets[i] == aug_targets[j]):\n",
    "                b = (np.sum((aug_set[i]-aug_set[j])**2))**0.5\n",
    "                a = np.append(a,b)\n",
    "        if np.min(a)==0:\n",
    "            conformity_scores[i] = inf\n",
    "        else:\n",
    "            conformity_scores[i] = 1/np.min(a)\n",
    "    test_conformity = conformity_scores[-1]\n",
    "    rank = np.sum(test_conformity >= conformity_scores)\n",
    "    p = rank/len(aug_set)\n",
    "    return p\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average False_Pvalue is:  0.021541686073591068\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_train)\n",
    "p_values =np.zeros((len(X_test), len(labels)))\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "conformity_scores = np.zeros(len(X_train)+1)\n",
    "for i in range(len(X_test)):\n",
    "    augmented_set = np.append(X_train, [X_test[i]],axis = 0)\n",
    "    for j in range(len(labels)):\n",
    "        augmented_targets = np.append(y_train, labels[j])\n",
    "        p_values[i][j] = calc_pvalue_2(augmented_set,augmented_targets)\n",
    "for i in range(len(p_values)):\n",
    "    pred_targets[i] = labels[np.argmax(p_values[i])]\n",
    "sum = 0    \n",
    "for i in range(len(p_values)):\n",
    "    k = int(pred_targets[i])\n",
    "    for j in range(len(labels)):\n",
    "        if p_values[i,k]!= p_values[i,j]:\n",
    "            sum =sum+ p_values[i,j]\n",
    "avg_false_p = sum/(len(p_values)*(len(labels)-1))\n",
    "print('The average False_Pvalue is: ',avg_false_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test error rate is : 0.07894736842105263\n",
      "Number of Misclassification : 3\n",
      "Success rate is : 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print('The Test error rate is :',np.mean(pred_targets != y_test))\n",
    "print('Number of Misclassification :',np.sum(pred_targets!=y_test))\n",
    "print('Success rate is :',np.mean(pred_targets == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**implementing nearest distance to a different class conformity measure for iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pvalue_3(aug_set,aug_targets):\n",
    "    for i in range(len(aug_set)):\n",
    "        c = np.array([])\n",
    "        for j in range(len(aug_set)):\n",
    "            if (i!=j) & (aug_targets[i] != aug_targets[j]):\n",
    "                b = (np.sum((aug_set[i]-aug_set[j])**2))**0.5\n",
    "                c = np.append(c,b)       \n",
    "        conformity_scores[i] = np.min(c)\n",
    "    test_conformity = conformity_scores[-1]\n",
    "    rank = np.sum(test_conformity >= conformity_scores)\n",
    "    p = rank/len(aug_set)\n",
    "    return p\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average False_Pvalue is:  0.03935724266418259\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_train)\n",
    "p_values =np.zeros((len(X_test), len(labels)))\n",
    "pred_targets = np.zeros(len(X_test))\n",
    "conformity_scores = np.zeros(len(X_train)+1)\n",
    "for i in range(len(X_test)):\n",
    "    augmented_set = np.append(X_train, [X_test[i]],axis = 0)\n",
    "    for j in range(len(labels)):\n",
    "        augmented_targets = np.append(y_train, labels[j])\n",
    "        p_values[i][j] = calc_pvalue_3(augmented_set,augmented_targets)\n",
    "for i in range(len(p_values)):\n",
    "    pred_targets[i] = labels[np.argmax(p_values[i])]\n",
    "sum = 0    \n",
    "for i in range(len(p_values)):\n",
    "    k = int(pred_targets[i])\n",
    "    for j in range(len(labels)):\n",
    "        if p_values[i,k]!= p_values[i,j]:\n",
    "            sum =sum+ p_values[i,j]\n",
    "avg_false_p = sum/(len(p_values)*(len(labels)-1))\n",
    "print('The average False_Pvalue is: ',avg_false_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test error rate is : 0.07894736842105263\n",
      "Number of Misclassification : 3\n",
      "Success rate is : 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print('The Test error rate is :',np.mean(pred_targets != y_test))\n",
    "print('Number of Misclassification :',np.sum(pred_targets!=y_test))\n",
    "print('Success rate is :',np.mean(pred_targets == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***observation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Using Conformal Predictors on Iris dataset using different conformity measures,the Test error rate and number of misclassifications remained same.\n",
    "Also, The results obtained by conformal predictors were similar to the results obtained via Nearest Neighbour algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KNN implementation for General K***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the value of K = 3 for example run on Ionosphere data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(iris_data.data,iris_data.target,random_state = 2810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =3\n",
    "y_pred = np.zeros(len(X_test))\n",
    "a = np.zeros(len(X_train))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_train)):\n",
    "        a[j] = E_len(X_train[j], X_test[i])\n",
    "    pos = np.argpartition(a,k)    \n",
    "    values = [ y_train[pos[h]] for h in range(k)]\n",
    "    temp = Counter(values)    \n",
    "    if temp.most_common(1)[0][1] == 1:\n",
    "        y_pred[i]= choice(np.unique(y_train))\n",
    "    else:\n",
    "        y_pred[i]=temp.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error rate is:  0.07894736842105263\n",
      "Number of Errors:  3\n"
     ]
    }
   ],
   "source": [
    "# Test error and no_of_error values\n",
    "test_error_rate = np.mean(y_pred != y_test)\n",
    "no_of_errors = np.sum(y_pred!=y_test)\n",
    "print('The Test Error rate is: ',test_error_rate)\n",
    "print('Number of Errors: ',no_of_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: K-Neighbours algorithm for k = 3 gave better results than Nearest Neighbour or Conformal Prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUMMARY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  Nearest Neighbor- Iris Dataset-  The Test Error rate is:  0.07894736842105263\n",
    "  \n",
    "  Nearest Neighbor- Ionosphere Dataset - The Test Error rate is:  0.10227272727272728\n",
    "  \n",
    "  Conformal Predictors - Iris Dataset- The average False_Pvalue is:  0.009548206800186318\n",
    "  \n",
    "  COnformal Predictors - Inonosphere Dataset- The average False_Pvalue is:  0.09999139118457302\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
